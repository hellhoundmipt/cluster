{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import jsonlines\n",
    "from os import listdir\n",
    "import itertools\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import pymorphy2 as pm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categories = [d['categories'] for d in data]\\ncategories = sorted(set(list(itertools.chain(*categories))))\\n\\ncategories_dict = {c: 0 for c in categories}\\nfor d in data:\\n    for c in d['categories']:\\n        if categories_dict.get(c) is not None:\\n            categories_dict[c] += 1\\n            \\nok = [c for c in categories if categories_dict[c] > 5 and categories_dict[c] < 5000]\\nok_set = set(ok)\\ncategories_dict = {d['id']: [c for c in d['categories'] if c in ok_set] for d in tqdm(data)}\\nlen(ok)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_set = set()\n",
    "with open(\"accepted_categories.txt\", mode=\"r\", encoding=\"utf-8\") as inp:\n",
    "    for line in inp:\n",
    "        line = line[:-1]\n",
    "        ok_set.add(line)\n",
    "\n",
    "ok = sorted(ok_set)\n",
    "\n",
    "categories_dict = {}\n",
    "with open(\"article_cat.json\", mode=\"r\") as input:\n",
    "    categories_dict = json.loads(input.read())\n",
    "    \n",
    "cat_id = {}\n",
    "with open(\"cat_id.json\", mode=\"r\") as input:\n",
    "    cat_id = json.loads(input.read())\n",
    "    \n",
    "id_cat ={}\n",
    "with open(\"id_cat.json\", mode=\"r\") as input:\n",
    "    id_cat = json.loads(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {item['id']: item['text'] for item in jsonlines.open('normalized_texts.jl', 'r')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.98)\n",
    "text_tfidf = vectorizer.fit_transform([text for (id, text) in sorted(texts.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"sources/text_tfidf\", text_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_tfidf = sorted([id for id in texts.keys()])\n",
    "#svd = TruncatedSVD(n_components=500, random_state=27)\n",
    "#X_tfidf = svd.fit_transform(text_tfidf)\n",
    "X_tfidf = text_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96791 96792 96793] TEST: [   56    71    93 ... 96715 96756 96789]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14697/14697 [1:27:11<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "X = X_tfidf\n",
    "ids = ids_tfidf\n",
    "\n",
    "kf = KFold(n_splits=20, shuffle=True, random_state=27)\n",
    "\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in kf.split(X):\n",
    "    train_index, test_index = item[0], item[1]\n",
    "    break\n",
    "    \n",
    "print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "X_train = X_tfidf[train_index]\n",
    "ids_train = [ids[i] for i in train_index]\n",
    "\n",
    "class_centroids = []\n",
    "for i, category in enumerate(tqdm(ok)):\n",
    "    clf_centroids = NearestCentroid()\n",
    "    y_train = np.array([1 if category in categories_dict[id] else 0 for id in ids_train])\n",
    "    if sum(y_train) > 0:\n",
    "        clf_centroids.fit(X_train, y_train)\n",
    "        class_centroids.append(csr_matrix(clf_centroids.centroids_[1]))\n",
    "    else:\n",
    "         print(category)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_centroids[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_class_centroids = lil_matrix((len(class_centroids), class_centroids[0].shape[1]))\n",
    "for i in range(len(class_centroids)):\n",
    "    _class_centroids[i] = class_centroids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"sources/sparce_centroids_nosvd\", _class_centroids.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([3, 4]), 2: array([3, 4])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "dict.fromkeys(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
