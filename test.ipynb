{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import collections\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv')\n",
    "data = list(zip(df['text'].tolist(), df['tags'].tolist()))\n",
    "tags = sorted(set(df['tags'].tolist()))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Катастрофы', 368), ('Бокс и ММА', 1379), ('Искусство', 1495), ('Внешний вид', 211), ('Следствие и суд', 4165), ('Прибалтика', 1043), ('Теннис', 930), ('Архитектура', 232), ('Мемы', 336), ('Футбол', 8678), ('Явления', 1345), ('Экология', 32), ('Наука', 5516), ('Госрегулирование', 41), ('Музыка', 3809), ('Госэкономика', 9190), ('Происшествия', 10858), ('Кино', 6592), ('Криминал', 1497), ('Производители', 36), ('История', 203), ('Мнения', 359), ('Средняя Азия', 936), ('Казахстан', 606), ('Первая мировая', 65), ('Наследие', 14), ('События', 2234), ('Игры', 1954), ('Мир', 1274), ('Москва', 1175), ('Банки', 1876), ('Украина', 13376), ('Книги', 939), ('Общество', 19437), ('Полиция и спецслужбы', 905), ('Авто', 24), ('Автобизнес', 242), ('Культпросвет', 1), ('Финансы компаний', 142), ('Страноведение', 10), ('Технологии', 200), ('Стиль', 1096), ('Туризм', 30), ('Летние виды', 2392), ('Деньги', 987), ('Политика', 22849), ('ТВ и радио', 1951), ('Оружие', 4120), ('Компании', 6626), ('Часы', 355), ('Реклама', 232), ('Крым', 3), ('Преступность', 3811), ('Выборы', 4), ('Инновации', 1), ('Гаджеты', 1816), ('Все', 450709), ('Регионы', 1304), ('Движение', 423), ('Кавказ', 1134), ('Звери', 1225), ('Хоккей', 381), ('Рынки', 1405), ('Вооруженные силы', 2973), ('Баскетбол', 573), ('Безопасность ', 41), ('Мировой бизнес', 680), ('Легпром', 4), ('Молдавия', 333), ('Белоруссия', 689), ('Ресурсы', 690), ('Зимние виды', 755), ('Техника', 936), ('Достижения', 368), ('Пресса', 1424), ('Инструменты', 397), ('Люди', 3696), ('Интернет', 5067), ('Деловой климат', 1598), ('Конфликты', 2061), ('Coцсети', 2039), ('Вирусные ролики', 196), ('Вооружение', 2), ('Мировой опыт', 6), ('Еда', 332), ('Вещи', 305), ('Театр', 882), ('Космос', 2576), ('Россия', 376), ('Вкусы', 11), ('Аналитика рынка', 28)]\n",
      "['Катастрофы', 'Бокс и ММА', 'Искусство', 'Внешний вид', 'Следствие и суд', 'Прибалтика', 'Теннис', 'Архитектура', 'Мемы', 'Футбол', 'Явления', 'Наука', 'Музыка', 'Госэкономика', 'Происшествия', 'Кино', 'Криминал', 'История', 'Мнения', 'Средняя Азия', 'Казахстан', 'События', 'Игры', 'Мир', 'Москва', 'Банки', 'Украина', 'Книги', 'Общество', 'Полиция и спецслужбы', 'Автобизнес', 'Финансы компаний', 'Технологии', 'Стиль', 'Летние виды', 'Деньги', 'Политика', 'ТВ и радио', 'Оружие', 'Компании', 'Часы', 'Реклама', 'Преступность', 'Гаджеты', 'Регионы', 'Движение', 'Кавказ', 'Звери', 'Хоккей', 'Рынки', 'Вооруженные силы', 'Баскетбол', 'Мировой бизнес', 'Молдавия', 'Белоруссия', 'Ресурсы', 'Зимние виды', 'Техника', 'Достижения', 'Пресса', 'Инструменты', 'Люди', 'Интернет', 'Деловой климат', 'Конфликты', 'Coцсети', 'Вирусные ролики', 'Еда', 'Вещи', 'Театр', 'Космос', 'Россия']\n"
     ]
    }
   ],
   "source": [
    "tags_cnt = list(Counter([d[1] for d in data]).items())\n",
    "tags_accepted = [tag[0] for tag in tags_cnt if tag[0] != 'Все' and tag[1] > 100]\n",
    "print(tags_cnt)\n",
    "print(tags_accepted)\n",
    "\n",
    "texts = [d[0] for d in data if d[1] in tags_accepted]\n",
    "text_tags = le.transform([d[1] for d in data if d[1] in tags_accepted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30759\n",
      "30760\n",
      "0 - 30759\n",
      "30759 - 61518\n",
      "61518 - 92277\n",
      "92277 - 123036\n",
      "123036 - 153795\n"
     ]
    }
   ],
   "source": [
    "corpus_size = len(texts)\n",
    "selections_num = 6      # На сколько частей разбиваем датасет\n",
    "selection_size = corpus_size // selections_num\n",
    "print(selection_size)\n",
    "print(corpus_size - (selections_num - 1) * selection_size)\n",
    "\n",
    "\n",
    "for i in range(selections_num - 1):\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    print(str(start) + ' - ' + str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируемся на первых пяти датасетах без лемматизации, проверяемся на шестом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection #0\n",
      "Training logistic regression\n",
      "Selection #1\n",
      "Training logistic regression\n",
      "Selection #2\n",
      "Training logistic regression\n",
      "Selection #3\n",
      "Training logistic regression\n",
      "Selection #4\n",
      "Training logistic regression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm\n",
    "\n",
    "\n",
    "def check_percentage(i, n):\n",
    "    r = i / n * 100\n",
    "    if r > 10 and  r < 10.01:\n",
    "        print(r)\n",
    "    elif r > 30 and  r < 30.01:\n",
    "        print(r)\n",
    "    elif r > 50 and  r < 50.01:\n",
    "        print(r)\n",
    "    elif r > 70 and  r < 70.01:\n",
    "        print(r)\n",
    "    elif r > 90 and  r < 90.01:\n",
    "        print(r)\n",
    "    \n",
    "\n",
    "morph = pm.MorphAnalyzer()\n",
    "stopwords_ru = [w for w in stopwords.words(\"russian\")]\n",
    "\n",
    "lin_reg_clf = Pipeline([('vect', CountVectorizer(stop_words = stopwords_ru)), \n",
    "             ('tfidf', TfidfTransformer()),\n",
    "             ('clf', LogisticRegression())\n",
    "               ])\n",
    "                \n",
    "lin_reg_models = []\n",
    "\n",
    "for i in range(selections_num - 1):\n",
    "    print(\"Selection #\" + str(i))\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    print(\"Training logistic regression\")\n",
    "    curr_texts = texts[start:end]\n",
    "    normalized_texts = []\n",
    "    \n",
    "    '''\n",
    "    n = len(curr_texts)\n",
    "    for i, text in enumerate(curr_texts):\n",
    "        check_percentage(i, n)\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        tokens = [morph.parse(t.lower())[0].normal_form for t in tokens if t.isalnum()]\n",
    "        normalized_texts.append(' '.join(tokens))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Yay \" + str(i))\n",
    "    print(\"Done lemmatization\")\n",
    "    '''\n",
    "    \n",
    "    lin_reg_models.append(lin_reg_clf.fit(curr_texts, text_tags[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625585175553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "start = (selections_num - 1) * selection_size\n",
    "test_selection_cnt = corpus_size - (selections_num - 1) * selection_size\n",
    "test_tags = text_tags[start:]\n",
    "\n",
    "'''\n",
    "X_test_counts = count_vect.fit(texts[start:])\n",
    "X_test_tfidf = tfidf_transformer.fit(X_test_counts)\n",
    "'''\n",
    "\n",
    "lin_reg_predictions = [model.predict(texts[start:]) for model in lin_reg_models]\n",
    "prediction = []\n",
    "#multinom_predictions = [model.predict(X_test_tfidf) for model in multinom_models\n",
    "for i in range(len(lin_reg_predictions[0])):\n",
    "    predictions = [p[i] for p in lin_reg_predictions]\n",
    "    prediction.append(max(set(predictions), key=predictions.count))\n",
    "\n",
    "\n",
    "prediction = np.array(prediction)\n",
    "log_reg_accuracy = accuracy_score(test_tags, prediction)\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ниже черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Деловой климат</td>\n",
       "      <td>Заместитель председателя правительства Аркадий...</td>\n",
       "      <td>Правительство прокомментировало идею о запрете...</td>\n",
       "      <td>Бизнес</td>\n",
       "      <td>https://lenta.ru/news/2017/04/01/24hours/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>События</td>\n",
       "      <td>Монреальская конвенция об унификации правил во...</td>\n",
       "      <td>Эксперт отвел год на окончательную ратификацию...</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>https://lenta.ru/news/2017/03/31/motrealwork/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Общество</td>\n",
       "      <td>Сотни байкеров в столице Аргентины Буэнос-Айре...</td>\n",
       "      <td>Аргентинские байкеры устроили акцию протеста п...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>https://lenta.ru/news/2017/03/30/bikers/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tags                                               text  \\\n",
       "0  Деловой климат  Заместитель председателя правительства Аркадий...   \n",
       "1         События  Монреальская конвенция об унификации правил во...   \n",
       "2        Общество  Сотни байкеров в столице Аргентины Буэнос-Айре...   \n",
       "\n",
       "                                               title        topic  \\\n",
       "0  Правительство прокомментировало идею о запрете...       Бизнес   \n",
       "1  Эксперт отвел год на окончательную ратификацию...  Путешествия   \n",
       "2  Аргентинские байкеры устроили акцию протеста п...          Мир   \n",
       "\n",
       "                                             url  \n",
       "0      https://lenta.ru/news/2017/04/01/24hours/  \n",
       "1  https://lenta.ru/news/2017/03/31/motrealwork/  \n",
       "2       https://lenta.ru/news/2017/03/30/bikers/  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['tags', 'text', 'title', 'topic', 'url']\n",
    "tags = [' спецпроект',\n",
    " 'Coцсети',\n",
    " 'Авто',\n",
    " 'Автобизнес',\n",
    " 'Аналитика рынка',\n",
    " 'Архитектура',\n",
    " 'Банки',\n",
    " 'Баскетбол',\n",
    " 'Безопасность ',\n",
    " 'Белоруссия',\n",
    " 'Бокс и ММА',\n",
    " 'Вещи',\n",
    " 'Вирусные ролики',\n",
    " 'Вкусы',\n",
    " 'Внешний вид',\n",
    " 'Вооружение',\n",
    " 'Вооруженные силы',\n",
    " 'Все',\n",
    " 'Выборы',\n",
    " 'Гаджеты',\n",
    " 'Госрегулирование',\n",
    " 'Госэкономика',\n",
    " 'Движение',\n",
    " 'Деловой климат',\n",
    " 'Деньги',\n",
    " 'Достижения',\n",
    " 'Еда',\n",
    " 'Звери',\n",
    " 'Зимние виды',\n",
    " 'Игры',\n",
    " 'Инновации',\n",
    " 'Инструменты',\n",
    " 'Интернет',\n",
    " 'Искусство',\n",
    " 'История',\n",
    " 'Кавказ',\n",
    " 'Казахстан',\n",
    " 'Катастрофы',\n",
    " 'Кино',\n",
    " 'Книги',\n",
    " 'Компании',\n",
    " 'Конфликты',\n",
    " 'Космос',\n",
    " 'Криминал',\n",
    " 'Крым',\n",
    " 'Культпросвет',\n",
    " 'Легпром',\n",
    " 'Летние виды',\n",
    " 'Люди',\n",
    " 'Мемы',\n",
    " 'Мир',\n",
    " 'Мировой бизнес',\n",
    " 'Мировой опыт',\n",
    " 'Мнения',\n",
    " 'Молдавия',\n",
    " 'Москва',\n",
    " 'Музыка',\n",
    " 'Наследие',\n",
    " 'Наука',\n",
    " 'Общество',\n",
    " 'Оружие',\n",
    " 'Первая мировая',\n",
    " 'Политика',\n",
    " 'Полиция и спецслужбы',\n",
    " 'Пресса',\n",
    " 'Преступность',\n",
    " 'Прибалтика',\n",
    " 'Производители',\n",
    " 'Происшествия',\n",
    " 'Регионы',\n",
    " 'Реклама',\n",
    " 'Ресурсы',\n",
    " 'Россия',\n",
    " 'Рынки',\n",
    " 'Следствие и суд',\n",
    " 'События',\n",
    " 'Средняя Азия',\n",
    " 'Стиль',\n",
    " 'Страноведение',\n",
    " 'ТВ и радио',\n",
    " 'Театр',\n",
    " 'Теннис',\n",
    " 'Техника',\n",
    " 'Технологии',\n",
    " 'Туризм',\n",
    " 'Украина',\n",
    " 'Финансы компаний',\n",
    " 'Футбол',\n",
    " 'Хоккей',\n",
    " 'Часы',\n",
    " 'Экология',\n",
    " 'Явления']\n",
    "\n",
    "num_tags = [{'tag': tag, 'id': i} for i, tag in enumerate(tags)]\n",
    "\n",
    "texts = []\n",
    "text_tags = []\n",
    "\n",
    "with codecs.open('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv', 'r', 'utf_8_sig') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        texts.append(row[1])\n",
    "        text_tags.append(next((tag['id'] for tag in num_tags if tag['tag'] == row[0]), None))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
