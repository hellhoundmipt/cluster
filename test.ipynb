{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import collections\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv')\n",
    "data = list(zip(df['text'].tolist(), df['tags'].tolist()))\n",
    "tags = sorted(set(df['tags'].tolist()))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Мнения', 359), ('Искусство', 1495), ('Выборы', 4), ('Россия', 376), ('Баскетбол', 573), ('Гаджеты', 1816), ('Происшествия', 10858), ('Технологии', 200), ('Движение', 423), ('Игры', 1954), ('Кавказ', 1134), ('Молдавия', 333), ('Легпром', 4), ('Деловой климат', 1598), ('Внешний вид', 211), ('Зимние виды', 755), ('Компании', 6626), ('Экология', 32), ('История', 203), ('Музыка', 3809), ('Ресурсы', 690), ('Финансы компаний', 142), ('Книги', 939), ('Аналитика рынка', 28), ('Часы', 355), ('Стиль', 1096), ('Казахстан', 606), ('Все', 450709), ('Общество', 19437), ('Прибалтика', 1043), ('Украина', 13376), ('Авто', 24), ('Политика', 22849), ('Средняя Азия', 936), ('Космос', 2576), ('Полиция и спецслужбы', 905), ('Инновации', 1), ('Люди', 3696), ('Хоккей', 381), ('Москва', 1175), ('Мировой бизнес', 680), ('Госэкономика', 9190), ('Вооруженные силы', 2973), ('Явления', 1345), ('Криминал', 1497), ('Рынки', 1405), ('Вирусные ролики', 196), ('Преступность', 3811), ('Банки', 1876), ('Реклама', 232), ('Госрегулирование', 41), ('Оружие', 4120), ('Мемы', 336), ('Крым', 3), ('Катастрофы', 368), ('Наследие', 14), ('Кино', 6592), ('Конфликты', 2061), ('Первая мировая', 65), ('Следствие и суд', 4165), ('Теннис', 930), ('Страноведение', 10), ('Наука', 5516), ('Автобизнес', 242), ('Вкусы', 11), ('Футбол', 8678), ('Культпросвет', 1), ('Безопасность ', 41), ('Инструменты', 397), ('Бокс и ММА', 1379), ('Еда', 332), ('Туризм', 30), ('Достижения', 368), ('Белоруссия', 689), ('Техника', 936), ('Пресса', 1424), ('Мировой опыт', 6), ('ТВ и радио', 1951), ('Звери', 1225), ('Coцсети', 2039), ('Регионы', 1304), ('Театр', 882), ('Вооружение', 2), ('Мир', 1274), ('Производители', 36), ('Деньги', 987), ('Вещи', 305), ('События', 2234), ('Летние виды', 2392), ('Архитектура', 232), ('Интернет', 5067)]\n",
      "['Мнения', 'Искусство', 'Россия', 'Баскетбол', 'Гаджеты', 'Происшествия', 'Технологии', 'Движение', 'Игры', 'Кавказ', 'Молдавия', 'Деловой климат', 'Внешний вид', 'Зимние виды', 'Компании', 'История', 'Музыка', 'Ресурсы', 'Финансы компаний', 'Книги', 'Часы', 'Стиль', 'Казахстан', 'Общество', 'Прибалтика', 'Украина', 'Политика', 'Средняя Азия', 'Космос', 'Полиция и спецслужбы', 'Люди', 'Хоккей', 'Москва', 'Мировой бизнес', 'Госэкономика', 'Вооруженные силы', 'Явления', 'Криминал', 'Рынки', 'Вирусные ролики', 'Преступность', 'Банки', 'Реклама', 'Оружие', 'Мемы', 'Катастрофы', 'Кино', 'Конфликты', 'Следствие и суд', 'Теннис', 'Наука', 'Автобизнес', 'Футбол', 'Инструменты', 'Бокс и ММА', 'Еда', 'Достижения', 'Белоруссия', 'Техника', 'Пресса', 'ТВ и радио', 'Звери', 'Coцсети', 'Регионы', 'Театр', 'Мир', 'Деньги', 'Вещи', 'События', 'Летние виды', 'Архитектура', 'Интернет']\n"
     ]
    }
   ],
   "source": [
    "tags_cnt = list(Counter([d[1] for d in data]).items())\n",
    "tags_accepted = [tag[0] for tag in tags_cnt if tag[0] != 'Все' and tag[1] > 100]\n",
    "print(tags_cnt)\n",
    "print(tags_accepted)\n",
    "\n",
    "texts = [d[0] for d in data if d[1] in tags_accepted]\n",
    "text_tags = le.transform([d[1] for d in data if d[1] in tags_accepted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30759\n",
      "30760\n",
      "0 - 30759\n",
      "30759 - 61518\n",
      "61518 - 92277\n",
      "92277 - 123036\n",
      "123036 - 153795\n"
     ]
    }
   ],
   "source": [
    "corpus_size = len(texts)\n",
    "selections_num = 6      # На сколько частей разбиваем датасет\n",
    "selection_size = corpus_size // selections_num\n",
    "print(selection_size)\n",
    "print(corpus_size - (selections_num - 1) * selection_size)\n",
    "\n",
    "\n",
    "for i in range(selections_num - 1):\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    print(str(start) + ' - ' + str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируемся на первых пяти датасетах без лемматизации, проверяемся на шестом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection #0\n",
      "Training logistic regression\n",
      "Yay 0\n",
      "Yay 1000\n",
      "Yay 2000\n",
      "Yay 3000\n",
      "10.000325108098442\n",
      "10.003576189082871\n",
      "10.006827270067298\n",
      "Yay 4000\n",
      "Yay 5000\n",
      "Yay 6000\n",
      "Yay 7000\n",
      "Yay 8000\n",
      "Yay 9000\n",
      "30.000975324295325\n",
      "30.004226405279756\n",
      "30.007477486264182\n",
      "Yay 10000\n",
      "Yay 11000\n",
      "Yay 12000\n",
      "Yay 13000\n",
      "Yay 14000\n",
      "Yay 15000\n",
      "50.00162554049221\n",
      "50.00487662147665\n",
      "50.00812770246107\n",
      "Yay 16000\n",
      "Yay 17000\n",
      "Yay 18000\n",
      "Yay 19000\n",
      "Yay 20000\n",
      "Yay 21000\n",
      "70.0022757566891\n",
      "70.00552683767353\n",
      "70.00877791865796\n",
      "Yay 22000\n",
      "Yay 23000\n",
      "Yay 24000\n",
      "Yay 25000\n",
      "Yay 26000\n",
      "Yay 27000\n",
      "90.00292597288599\n",
      "90.0061770538704\n",
      "90.00942813485484\n",
      "Yay 28000\n",
      "Yay 29000\n",
      "Yay 30000\n",
      "Done lemmatization\n",
      "Selection #1\n",
      "Training logistic regression\n",
      "Yay 0\n",
      "Yay 1000\n",
      "Yay 2000\n",
      "Yay 3000\n",
      "10.000325108098442\n",
      "10.003576189082871\n",
      "10.006827270067298\n",
      "Yay 4000\n",
      "Yay 5000\n",
      "Yay 6000\n",
      "Yay 7000\n",
      "Yay 8000\n",
      "Yay 9000\n",
      "30.000975324295325\n",
      "30.004226405279756\n",
      "30.007477486264182\n",
      "Yay 10000\n",
      "Yay 11000\n",
      "Yay 12000\n",
      "Yay 13000\n",
      "Yay 14000\n",
      "Yay 15000\n",
      "50.00162554049221\n",
      "50.00487662147665\n",
      "50.00812770246107\n",
      "Yay 16000\n",
      "Yay 17000\n",
      "Yay 18000\n",
      "Yay 19000\n",
      "Yay 20000\n",
      "Yay 21000\n",
      "70.0022757566891\n",
      "70.00552683767353\n",
      "70.00877791865796\n",
      "Yay 22000\n",
      "Yay 23000\n",
      "Yay 24000\n",
      "Yay 25000\n",
      "Yay 26000\n",
      "Yay 27000\n",
      "90.00292597288599\n",
      "90.0061770538704\n",
      "90.00942813485484\n",
      "Yay 28000\n",
      "Yay 29000\n",
      "Yay 30000\n",
      "Done lemmatization\n",
      "Selection #2\n",
      "Training logistic regression\n",
      "Yay 0\n",
      "Yay 1000\n",
      "Yay 2000\n",
      "Yay 3000\n",
      "10.000325108098442\n",
      "10.003576189082871\n",
      "10.006827270067298\n",
      "Yay 4000\n",
      "Yay 5000\n",
      "Yay 6000\n",
      "Yay 7000\n",
      "Yay 8000\n",
      "Yay 9000\n",
      "30.000975324295325\n",
      "30.004226405279756\n",
      "30.007477486264182\n",
      "Yay 10000\n",
      "Yay 11000\n",
      "Yay 12000\n",
      "Yay 13000\n",
      "Yay 14000\n",
      "Yay 15000\n",
      "50.00162554049221\n",
      "50.00487662147665\n",
      "50.00812770246107\n",
      "Yay 16000\n",
      "Yay 17000\n",
      "Yay 18000\n",
      "Yay 19000\n",
      "Yay 20000\n",
      "Yay 21000\n",
      "70.0022757566891\n",
      "70.00552683767353\n",
      "70.00877791865796\n",
      "Yay 22000\n",
      "Yay 23000\n",
      "Yay 24000\n",
      "Yay 25000\n",
      "Yay 26000\n",
      "Yay 27000\n",
      "90.00292597288599\n",
      "90.0061770538704\n",
      "90.00942813485484\n",
      "Yay 28000\n",
      "Yay 29000\n",
      "Yay 30000\n",
      "Done lemmatization\n",
      "Selection #3\n",
      "Training logistic regression\n",
      "Yay 0\n",
      "Yay 1000\n",
      "Yay 2000\n",
      "Yay 3000\n",
      "10.000325108098442\n",
      "10.003576189082871\n",
      "10.006827270067298\n",
      "Yay 4000\n",
      "Yay 5000\n",
      "Yay 6000\n",
      "Yay 7000\n",
      "Yay 8000\n",
      "Yay 9000\n",
      "30.000975324295325\n",
      "30.004226405279756\n",
      "30.007477486264182\n",
      "Yay 10000\n",
      "Yay 11000\n",
      "Yay 12000\n",
      "Yay 13000\n",
      "Yay 14000\n",
      "Yay 15000\n",
      "50.00162554049221\n",
      "50.00487662147665\n",
      "50.00812770246107\n",
      "Yay 16000\n",
      "Yay 17000\n",
      "Yay 18000\n",
      "Yay 19000\n",
      "Yay 20000\n",
      "Yay 21000\n",
      "70.0022757566891\n",
      "70.00552683767353\n",
      "70.00877791865796\n",
      "Yay 22000\n",
      "Yay 23000\n",
      "Yay 24000\n",
      "Yay 25000\n",
      "Yay 26000\n",
      "Yay 27000\n",
      "90.00292597288599\n",
      "90.0061770538704\n",
      "90.00942813485484\n",
      "Yay 28000\n",
      "Yay 29000\n",
      "Yay 30000\n",
      "Done lemmatization\n",
      "Selection #4\n",
      "Training logistic regression\n",
      "Yay 0\n",
      "Yay 1000\n",
      "Yay 2000\n",
      "Yay 3000\n",
      "10.000325108098442\n",
      "10.003576189082871\n",
      "10.006827270067298\n",
      "Yay 4000\n",
      "Yay 5000\n",
      "Yay 6000\n",
      "Yay 7000\n",
      "Yay 8000\n",
      "Yay 9000\n",
      "30.000975324295325\n",
      "30.004226405279756\n",
      "30.007477486264182\n",
      "Yay 10000\n",
      "Yay 11000\n",
      "Yay 12000\n",
      "Yay 13000\n",
      "Yay 14000\n",
      "Yay 15000\n",
      "50.00162554049221\n",
      "50.00487662147665\n",
      "50.00812770246107\n",
      "Yay 16000\n",
      "Yay 17000\n",
      "Yay 18000\n",
      "Yay 19000\n",
      "Yay 20000\n",
      "Yay 21000\n",
      "70.0022757566891\n",
      "70.00552683767353\n",
      "70.00877791865796\n",
      "Yay 22000\n",
      "Yay 23000\n",
      "Yay 24000\n",
      "Yay 25000\n",
      "Yay 26000\n",
      "Yay 27000\n",
      "90.00292597288599\n",
      "90.0061770538704\n",
      "90.00942813485484\n",
      "Yay 28000\n",
      "Yay 29000\n",
      "Yay 30000\n",
      "Done lemmatization\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm\n",
    "\n",
    "\n",
    "def check_percentage(i, n):\n",
    "    r = i / n * 100\n",
    "    if r > 10 and  r < 10.01:\n",
    "        print(r)\n",
    "    elif r > 30 and  r < 30.01:\n",
    "        print(r)\n",
    "    elif r > 50 and  r < 50.01:\n",
    "        print(r)\n",
    "    elif r > 70 and  r < 70.01:\n",
    "        print(r)\n",
    "    elif r > 90 and  r < 90.01:\n",
    "        print(r)\n",
    "    \n",
    "\n",
    "morph = pm.MorphAnalyzer()\n",
    "stopwords_ru = [w for w in stopwords.words(\"russian\")]\n",
    "\n",
    "lin_reg_clf = Pipeline([('vect', CountVectorizer(stop_words = stopwords_ru)), \n",
    "             ('tfidf', TfidfTransformer()),\n",
    "             ('clf', LogisticRegression())\n",
    "               ])\n",
    "                \n",
    "lin_reg_models = []\n",
    "\n",
    "for i in range(selections_num - 1):\n",
    "    print(\"Selection #\" + str(i))\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    print(\"Training logistic regression\")\n",
    "    curr_texts = texts[start:end]\n",
    "    normalized_texts = []\n",
    "    \n",
    "    \n",
    "    n = len(curr_texts)\n",
    "    for i, text in enumerate(curr_texts):\n",
    "        check_percentage(i, n)\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        tokens = [morph.parse(t.lower())[0].normal_form for t in tokens if t.isalnum()]\n",
    "        normalized_texts.append(' '.join(tokens))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Yay \" + str(i))\n",
    "    print(\"Done lemmatization\")\n",
    "    \n",
    "    \n",
    "    lin_reg_models.append(lin_reg_clf.fit(normalized_texts, text_tags[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517067620286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "start = (selections_num - 1) * selection_size\n",
    "test_selection_cnt = corpus_size - (selections_num - 1) * selection_size\n",
    "test_tags = text_tags[start:]\n",
    "\n",
    "'''\n",
    "X_test_counts = count_vect.fit(texts[start:])\n",
    "X_test_tfidf = tfidf_transformer.fit(X_test_counts)\n",
    "'''\n",
    "\n",
    "lin_reg_predictions = [model.predict(texts[start:]) for model in lin_reg_models]\n",
    "prediction = []\n",
    "#multinom_predictions = [model.predict(X_test_tfidf) for model in multinom_models\n",
    "for i in range(len(lin_reg_predictions[0])):\n",
    "    predictions = [p[i] for p in lin_reg_predictions]\n",
    "    prediction.append(max(set(predictions), key=predictions.count))\n",
    "\n",
    "\n",
    "prediction = np.array(prediction)\n",
    "log_reg_accuracy = accuracy_score(test_tags, prediction)\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ниже черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Деловой климат</td>\n",
       "      <td>Заместитель председателя правительства Аркадий...</td>\n",
       "      <td>Правительство прокомментировало идею о запрете...</td>\n",
       "      <td>Бизнес</td>\n",
       "      <td>https://lenta.ru/news/2017/04/01/24hours/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>События</td>\n",
       "      <td>Монреальская конвенция об унификации правил во...</td>\n",
       "      <td>Эксперт отвел год на окончательную ратификацию...</td>\n",
       "      <td>Путешествия</td>\n",
       "      <td>https://lenta.ru/news/2017/03/31/motrealwork/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Общество</td>\n",
       "      <td>Сотни байкеров в столице Аргентины Буэнос-Айре...</td>\n",
       "      <td>Аргентинские байкеры устроили акцию протеста п...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>https://lenta.ru/news/2017/03/30/bikers/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tags                                               text  \\\n",
       "0  Деловой климат  Заместитель председателя правительства Аркадий...   \n",
       "1         События  Монреальская конвенция об унификации правил во...   \n",
       "2        Общество  Сотни байкеров в столице Аргентины Буэнос-Айре...   \n",
       "\n",
       "                                               title        topic  \\\n",
       "0  Правительство прокомментировало идею о запрете...       Бизнес   \n",
       "1  Эксперт отвел год на окончательную ратификацию...  Путешествия   \n",
       "2  Аргентинские байкеры устроили акцию протеста п...          Мир   \n",
       "\n",
       "                                             url  \n",
       "0      https://lenta.ru/news/2017/04/01/24hours/  \n",
       "1  https://lenta.ru/news/2017/03/31/motrealwork/  \n",
       "2       https://lenta.ru/news/2017/03/30/bikers/  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['tags', 'text', 'title', 'topic', 'url']\n",
    "tags = [' спецпроект',\n",
    " 'Coцсети',\n",
    " 'Авто',\n",
    " 'Автобизнес',\n",
    " 'Аналитика рынка',\n",
    " 'Архитектура',\n",
    " 'Банки',\n",
    " 'Баскетбол',\n",
    " 'Безопасность ',\n",
    " 'Белоруссия',\n",
    " 'Бокс и ММА',\n",
    " 'Вещи',\n",
    " 'Вирусные ролики',\n",
    " 'Вкусы',\n",
    " 'Внешний вид',\n",
    " 'Вооружение',\n",
    " 'Вооруженные силы',\n",
    " 'Все',\n",
    " 'Выборы',\n",
    " 'Гаджеты',\n",
    " 'Госрегулирование',\n",
    " 'Госэкономика',\n",
    " 'Движение',\n",
    " 'Деловой климат',\n",
    " 'Деньги',\n",
    " 'Достижения',\n",
    " 'Еда',\n",
    " 'Звери',\n",
    " 'Зимние виды',\n",
    " 'Игры',\n",
    " 'Инновации',\n",
    " 'Инструменты',\n",
    " 'Интернет',\n",
    " 'Искусство',\n",
    " 'История',\n",
    " 'Кавказ',\n",
    " 'Казахстан',\n",
    " 'Катастрофы',\n",
    " 'Кино',\n",
    " 'Книги',\n",
    " 'Компании',\n",
    " 'Конфликты',\n",
    " 'Космос',\n",
    " 'Криминал',\n",
    " 'Крым',\n",
    " 'Культпросвет',\n",
    " 'Легпром',\n",
    " 'Летние виды',\n",
    " 'Люди',\n",
    " 'Мемы',\n",
    " 'Мир',\n",
    " 'Мировой бизнес',\n",
    " 'Мировой опыт',\n",
    " 'Мнения',\n",
    " 'Молдавия',\n",
    " 'Москва',\n",
    " 'Музыка',\n",
    " 'Наследие',\n",
    " 'Наука',\n",
    " 'Общество',\n",
    " 'Оружие',\n",
    " 'Первая мировая',\n",
    " 'Политика',\n",
    " 'Полиция и спецслужбы',\n",
    " 'Пресса',\n",
    " 'Преступность',\n",
    " 'Прибалтика',\n",
    " 'Производители',\n",
    " 'Происшествия',\n",
    " 'Регионы',\n",
    " 'Реклама',\n",
    " 'Ресурсы',\n",
    " 'Россия',\n",
    " 'Рынки',\n",
    " 'Следствие и суд',\n",
    " 'События',\n",
    " 'Средняя Азия',\n",
    " 'Стиль',\n",
    " 'Страноведение',\n",
    " 'ТВ и радио',\n",
    " 'Театр',\n",
    " 'Теннис',\n",
    " 'Техника',\n",
    " 'Технологии',\n",
    " 'Туризм',\n",
    " 'Украина',\n",
    " 'Финансы компаний',\n",
    " 'Футбол',\n",
    " 'Хоккей',\n",
    " 'Часы',\n",
    " 'Экология',\n",
    " 'Явления']\n",
    "\n",
    "num_tags = [{'tag': tag, 'id': i} for i, tag in enumerate(tags)]\n",
    "\n",
    "texts = []\n",
    "text_tags = []\n",
    "\n",
    "with codecs.open('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv', 'r', 'utf_8_sig') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        texts.append(row[1])\n",
    "        text_tags.append(next((tag['id'] for tag in num_tags if tag['tag'] == row[0]), None))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
