{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import collections\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['tags', 'text', 'title', 'topic', 'url']\n",
    "tags = [' спецпроект',\n",
    " 'Coцсети',\n",
    " 'Авто',\n",
    " 'Автобизнес',\n",
    " 'Аналитика рынка',\n",
    " 'Архитектура',\n",
    " 'Банки',\n",
    " 'Баскетбол',\n",
    " 'Безопасность ',\n",
    " 'Белоруссия',\n",
    " 'Бокс и ММА',\n",
    " 'Вещи',\n",
    " 'Вирусные ролики',\n",
    " 'Вкусы',\n",
    " 'Внешний вид',\n",
    " 'Вооружение',\n",
    " 'Вооруженные силы',\n",
    " 'Все',\n",
    " 'Выборы',\n",
    " 'Гаджеты',\n",
    " 'Госрегулирование',\n",
    " 'Госэкономика',\n",
    " 'Движение',\n",
    " 'Деловой климат',\n",
    " 'Деньги',\n",
    " 'Достижения',\n",
    " 'Еда',\n",
    " 'Звери',\n",
    " 'Зимние виды',\n",
    " 'Игры',\n",
    " 'Инновации',\n",
    " 'Инструменты',\n",
    " 'Интернет',\n",
    " 'Искусство',\n",
    " 'История',\n",
    " 'Кавказ',\n",
    " 'Казахстан',\n",
    " 'Катастрофы',\n",
    " 'Кино',\n",
    " 'Книги',\n",
    " 'Компании',\n",
    " 'Конфликты',\n",
    " 'Космос',\n",
    " 'Криминал',\n",
    " 'Крым',\n",
    " 'Культпросвет',\n",
    " 'Легпром',\n",
    " 'Летние виды',\n",
    " 'Люди',\n",
    " 'Мемы',\n",
    " 'Мир',\n",
    " 'Мировой бизнес',\n",
    " 'Мировой опыт',\n",
    " 'Мнения',\n",
    " 'Молдавия',\n",
    " 'Москва',\n",
    " 'Музыка',\n",
    " 'Наследие',\n",
    " 'Наука',\n",
    " 'Общество',\n",
    " 'Оружие',\n",
    " 'Первая мировая',\n",
    " 'Политика',\n",
    " 'Полиция и спецслужбы',\n",
    " 'Пресса',\n",
    " 'Преступность',\n",
    " 'Прибалтика',\n",
    " 'Производители',\n",
    " 'Происшествия',\n",
    " 'Регионы',\n",
    " 'Реклама',\n",
    " 'Ресурсы',\n",
    " 'Россия',\n",
    " 'Рынки',\n",
    " 'Следствие и суд',\n",
    " 'События',\n",
    " 'Средняя Азия',\n",
    " 'Стиль',\n",
    " 'Страноведение',\n",
    " 'ТВ и радио',\n",
    " 'Театр',\n",
    " 'Теннис',\n",
    " 'Техника',\n",
    " 'Технологии',\n",
    " 'Туризм',\n",
    " 'Украина',\n",
    " 'Финансы компаний',\n",
    " 'Футбол',\n",
    " 'Хоккей',\n",
    " 'Часы',\n",
    " 'Экология',\n",
    " 'Явления']\n",
    "\n",
    "num_tags = [{'tag': tag, 'id': i} for i, tag in enumerate(tags)]\n",
    "\n",
    "texts = []\n",
    "text_tags = []\n",
    "\n",
    "with codecs.open('D:\\Max\\docs_cluster\\lenta\\lenta_data.csv', 'r', 'utf_8_sig') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        texts.append(row[1])\n",
    "        text_tags.append(next((tag['id'] for tag in num_tags if tag['tag'] == row[0]), None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105936\n",
      "105938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(selections_num - 1):\\n    start = i * selection_size\\n    end = start + selection_size\\n    print(str(start) + ' - ' + str(end))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(5):\n",
    "    print(texts[i])\n",
    "    print(text_tags[i])\n",
    "'''\n",
    "\n",
    "corpus_size = len(texts)\n",
    "selections_num = 6      # На сколько частей разбиваем датасет\n",
    "selection_size = corpus_size // selections_num\n",
    "print(selection_size)\n",
    "print(corpus_size - (selections_num - 1) * selection_size)\n",
    "\n",
    "'''\n",
    "for i in range(selections_num - 1):\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    print(str(start) + ' - ' + str(end))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируемся на первых пяти датасетах без лемматизации, проверяемся на шестом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection #0\n",
      "Training logistic regression\n",
      "Selection #1\n",
      "Training logistic regression\n",
      "Selection #2\n",
      "Training logistic regression\n",
      "Selection #3\n",
      "Training logistic regression\n",
      "Selection #4\n",
      "Training logistic regression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "count_vect = CountVectorizer()\n",
    "lin_reg_models = []\n",
    "multinom_models = []\n",
    "\n",
    "for i in range(selections_num - 1):\n",
    "    print(\"Selection #\" + str(i))\n",
    "    start = i * selection_size\n",
    "    end = start + selection_size\n",
    "    X_train_counts = count_vect.fit_transform(texts[start:end])\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    print(\"Training logistic regression\")\n",
    "    lin_reg_models.append(LogisticRegression().fit(X_train_tfidf, text_tags[start:end]))\n",
    "    #print(\"Training multinomialNB\")\n",
    "    #multinom_models.append(MultinomialNB().fit(X_train_tfidf, text_tags[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 440699 features per sample; expecting 442020",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b1ef7ce0fadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_test_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlin_reg_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlin_reg_models\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmultinom_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmultinom_models\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b1ef7ce0fadb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_test_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlin_reg_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlin_reg_models\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmultinom_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmultinom_models\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Maxim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 249\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 440699 features per sample; expecting 442020"
     ]
    }
   ],
   "source": [
    "log_reg_hit = 0     #сколько раз классификатор угадал при проверке\n",
    "multinom_hit = 0\n",
    "\n",
    "\n",
    "start = (selections_num - 1) * selection_size\n",
    "test_selection_cnt = corpus_size - (selections_num - 1) * selection_size\n",
    "test_tags = text_tags[start:]\n",
    "\n",
    "X_test_counts = count_vect.fit_transform(texts[start:])\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "\n",
    "lin_reg_predictions = [model.predict(X_test_tfidf) for model in lin_reg_models]\n",
    "multinom_predictions = [model.predict(X_test_tfidf) for model in multinom_models]\n",
    "\n",
    "for i in range(7):\n",
    "    predictions = [p[i] for p in lin_reg_predictions]\n",
    "    prediction = max(set(predictions), key=lst.count)\n",
    "    if test_tags[i] == prediction:\n",
    "        log_reg_hit += 1\n",
    "\n",
    "\n",
    "log_reg_accuracy = log_reg_hit / test_selection_cnt\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ниже черновик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
