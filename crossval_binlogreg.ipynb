{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import jsonlines\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm\n",
    "import networkx as nx\n",
    "import re\n",
    "from bisect import bisect_left\n",
    "#from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from random import shuffle\n",
    "from sys import exit\n",
    "import numpy as np\n",
    "import json\n",
    "import codecs\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "#nltk.download()\n",
    "tknzr = nltk.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_set = set()\n",
    "with open(\"sources/accepted_categories.txt\", mode=\"r\", encoding=\"utf-8\") as inp:\n",
    "    for line in inp:\n",
    "        line = line[:-1]\n",
    "        ok_set.add(line)\n",
    "\n",
    "ok = sorted(ok_set)\n",
    "\n",
    "categories_dict = {}\n",
    "with open(\"sources/article_cat.json\", mode=\"r\") as input:\n",
    "    categories_dict = json.loads(input.read())\n",
    "    \n",
    "category_article = {}\n",
    "with open(\"sources/cat_article.json\", mode=\"r\") as input:\n",
    "    category_article = json.loads(input.read())\n",
    "    \n",
    "X = load_npz(\"sources/text_tfidf.npz\")\n",
    "    \n",
    "texts = {item['id']: item['text'] for item in jsonlines.open('sources/normalized_texts.jl', 'r')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted([id for id in texts.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.98)\n",
    "text_tfidf = vectorizer.fit_transform([text for (id, text) in sorted(texts.items())])\n",
    "#svd = TruncatedSVD(n_components=500, random_state=27)\n",
    "#X_svd = svd.fit_transform(text_tfidf)\n",
    "X = text_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest = 5\n",
    "'''class_centroids = {}\n",
    "with open(\"sources/centroids.json\", \"r\") as input:\n",
    "    class_centroids = json.loads(input.read())\n",
    "'''\n",
    "class_centroids = load_npz(\"sources/sparce_centroids_nosvd.npz\")\n",
    "\n",
    "kn_clust = NearestNeighbors(n_neighbors=k_nearest)\n",
    "#kn_clust.fit([centroid for (cat, centroid) in sorted(class_centroids.items())])\n",
    "kn_clust.fit(class_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14697, 121303)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96794, 121303)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96791 96792 96793] TEST: [    4     7    27 ... 96770 96779 96789]\n",
      "77435 19359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 77435/77435 [00:27<00:00, 2835.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [03:07<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387175, 121303)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-841e3eb9f033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_right\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    891\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=27)\n",
    "clf = LogisticRegression(C=1.0, class_weight=\"balanced\")\n",
    "X_train = []\n",
    "X_right = []\n",
    "X_left = []\n",
    "y_train = []\n",
    "rows = []\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in kf.split(ids):\n",
    "    \n",
    "    score = 0\n",
    "    train_index, test_index = item[0], item[1]\n",
    "    \n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "    \n",
    "    X_left[:] = []\n",
    "    for i in trange(len(train_index)):\n",
    "        for j in range(k_nearest):\n",
    "            X_left.append(X[train_index[i]])\n",
    "            \n",
    "    X_left = vstack(X_left)\n",
    "    X_right[:] = []\n",
    "    y_train[:] = []\n",
    "    rows[:] = []\n",
    "    print(\"Train!\")\n",
    "    batchsize = 1000\n",
    "    for i in trange(0, len(train_index), batchsize):\n",
    "        batch = train_index[i:i+batchsize]\n",
    "        curr_x = X[batch]\n",
    "        _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "        \n",
    "        for j, neighbors in enumerate(_neighbors):  \n",
    "            cats = categories_dict[ids[i+j]]\n",
    "            neighbors = [ok[c] for c in neighbors]\n",
    "            common = set(neighbors).intersection(set(cats))\n",
    "            for neigh in neighbors:\n",
    "                rows.append(ok.index(neigh))\n",
    "                y_train.append(1 if neigh in common else 0)\n",
    "    \n",
    "    X_right = X[rows]\n",
    "    print(X_right.shape)\n",
    "    print(X_left.shape)\n",
    "    X_train = hstack([X_left, X_right])\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Test!\")\n",
    "    for index in tqdm(test_index):\n",
    "        result = ids[index]\n",
    "        test_svd = X[index]\n",
    "        y_true = np.array(categories_dict[result])\n",
    "        X_local = []\n",
    "        local_skipped = []\n",
    "        prediction = []\n",
    "        rows[:] = []\n",
    "        for i, y in enumerate(y_true):\n",
    "            if ok.index(y) is not None:\n",
    "                rows.append(ok.index(y))\n",
    "            else:\n",
    "                local_skipped.append((i, y))\n",
    "                \n",
    "        test_svd = vstack([test_svd] * class_centroids[rows].shape[0])\n",
    "        X_local = hstack([test_svd, class_centroids[rows]])\n",
    "        if X_local.shape[0] > 0:\n",
    "            prediction = clf.predict(X_local)\n",
    "        for item in local_skipped:\n",
    "            prediction.insert(item[0], 1)\n",
    "            \n",
    "        score += sum(prediction) / len(y_true)\n",
    "    \n",
    "    print(score / len(test_index))   \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387175, 242606)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.0, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/19359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00088934 0.00091905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-e2603e8062fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "for index in tqdm(test_index):\n",
    "    result = ids[index]\n",
    "    test_svd = X[index]\n",
    "    y_true = np.array(categories_dict[result])\n",
    "    X_local = []\n",
    "    local_skipped = []\n",
    "    prediction = []\n",
    "    rows[:] = []\n",
    "    for i, y in enumerate(y_true):\n",
    "        if ok.index(y) is not None:\n",
    "            rows.append(ok.index(y))\n",
    "        else:\n",
    "            local_skipped.append((i, y))\n",
    "    \n",
    "    test_svd = vstack([test_svd] * class_centroids[rows].shape[0])\n",
    "    X_local = hstack([test_svd, class_centroids[rows]])\n",
    "    if X_local.shape[0] > 0:\n",
    "        prediction = clf.predict_proba(X_local)[:,1]\n",
    "    for item in local_skipped:\n",
    "        prediction.insert(item[0], 1)\n",
    "\n",
    "    score += sum(prediction) / len(y_true)\n",
    "    print(prediction)\n",
    "    print(roc_auc_score([1] * len(y_true), prediction))\n",
    "    \n",
    "    break\n",
    "#print(score / len(test_index))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обычный cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96794it [00:04, 23562.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [04:02<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "X_left = []\n",
    "for x in tqdm(X):\n",
    "    for j in range(k_nearest):\n",
    "        X_left.append(x)       \n",
    "X_left = vstack(X_left)\n",
    "\n",
    "X_right = []\n",
    "y_train[:] = []\n",
    "rows[:] = []\n",
    "batchsize = 1000\n",
    "for i in trange(0, X.shape[0], batchsize):\n",
    "    curr_x = X[i:i+batchsize]\n",
    "    _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "    \n",
    "    for j, neighbors in enumerate(_neighbors):\n",
    "        cats = categories_dict[ids[i+j]]\n",
    "        neighbors = [ok[c] for c in neighbors]\n",
    "        common = set(neighbors).intersection(set(cats))\n",
    "        for neigh in neighbors:\n",
    "            rows.append(ok.index(neigh))\n",
    "            y_train.append(1 if neigh in common else 0)\n",
    "            \n",
    "\n",
    "X_right = X[rows]\n",
    "X_full = hstack([X_left, X_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483970, 242606)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192465"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65530246, 0.62893164, 0.59896771])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_full, y_train, n_jobs=-1, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем модельку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96791 96792 96793] TEST: [    4     7    27 ... 96770 96779 96789]\n",
      "77435 19359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96794it [00:03, 24582.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [03:59<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=27)\n",
    "clf = LogisticRegression(C=1.0, class_weight=\"balanced\")\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in kf.split(ids):\n",
    "    \n",
    "    score = 0\n",
    "    train_index, test_index = item[0], item[1]\n",
    "    \n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "    break\n",
    "    \n",
    "    \n",
    "X_left = []\n",
    "for x in tqdm(X):\n",
    "    for j in range(k_nearest):\n",
    "        X_left.append(x)       \n",
    "X_left = vstack(X_left)\n",
    "\n",
    "X_right = []\n",
    "y = []\n",
    "rows = []\n",
    "batchsize = 1000\n",
    "for i in trange(0, X.shape[0], batchsize):\n",
    "    curr_x = X[i:i+batchsize]\n",
    "    _neighbors = kn_clust.kneighbors(curr_x, n_neighbors=k_nearest, return_distance=False)\n",
    "    \n",
    "    for j, neighbors in enumerate(_neighbors):\n",
    "        cats = categories_dict[ids[i+j]]\n",
    "        neighbors = [ok[c] for c in neighbors]\n",
    "        common = set(neighbors).intersection(set(cats))\n",
    "        for neigh in neighbors:\n",
    "            rows.append(ok.index(neigh))\n",
    "            y.append(1 if neigh in common else 0)\n",
    "\n",
    "X_right = X[rows]\n",
    "X_full = hstack([X_left, X_right])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_full.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_full[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sources/clf_binlogreg.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, \"sources/clf_binlogreg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
