{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import jsonlines\n",
    "from scipy import sparse\n",
    "from os import listdir\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "import pymorphy2 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "tknzr = TweetTokenizer()\n",
    "morph = pm.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_set = set()\n",
    "with open(\"sources/accepted_categories.txt\", mode=\"r\", encoding=\"utf-8\") as inp:\n",
    "    for line in inp:\n",
    "        line = line[:-1]\n",
    "        ok_set.add(line)\n",
    "\n",
    "ok = sorted(ok_set)\n",
    "\n",
    "categories_dict = {}\n",
    "with open(\"sources/article_cat.json\", mode=\"r\") as input:\n",
    "    categories_dict = json.loads(input.read())\n",
    "    \n",
    "cat_id = {}\n",
    "with open(\"sources/cat_id.json\", mode=\"r\") as input:\n",
    "    cat_id = json.loads(input.read())\n",
    "    \n",
    "id_cat ={}\n",
    "with open(\"sources/id_cat.json\", mode=\"r\") as input:\n",
    "    id_cat = json.loads(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_binlogreg = joblib.load(\"sources/clf_binlogreg.pkl\")\n",
    "X = load_npz(\"sources/text_tfidf.npz\")\n",
    "class_centroids = load_npz(\"sources/sparce_centroids_nosvd.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted([item['id'] for item in jsonlines.open('sources/normalized_texts.jl', 'r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_centroids = np.diag([1] * len(ok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNN:\n",
    "    \n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.clf = NearestNeighbors(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.clf.fit(X_train)\n",
    "        self.categories = y_train\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test, n_neighbors=None):\n",
    "        if n_neighbors is None:\n",
    "            n_neighbors = self.n_neighbors\n",
    "            \n",
    "        kneighbors = self.clf.kneighbors(X_test, n_neighbors, return_distance=False)\n",
    "        res = []\n",
    "        for neighs in kneighbors:\n",
    "            curr_neigh = np.zeros(self.categories.shape[1], dtype=int)\n",
    "            for neigh in neighs:\n",
    "                curr_neigh = np.bitwise_or(self.categories[neigh], curr_neigh)\n",
    "            res.append(curr_neigh)\n",
    "        \n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(res, true):\n",
    "    if len(res) == 0:\n",
    "        return 0\n",
    "    \n",
    "    hits = 0\n",
    "    for c in res:\n",
    "        if c in true:\n",
    "            hits += 1\n",
    "    return hits / len(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = KNeighborsClassifier(n_neighbors=1, n_jobs=-1, weights='distance')\n",
    "n_neighbors = 15\n",
    "clf = CustomKNN(n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(class_centroids, y_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тут просто custom knn на центроидах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96791 96792 96793] TEST: [    4     7    27 ... 96770 96779 96789]\n",
      "77435 19359\n",
      "0.3525388708093805\n",
      "0.7522821981098591\n",
      "0.48009351760657765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [05:09, 309.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96790 96792 96793] TEST: [    3    10    13 ... 96785 96788 96791]\n",
      "77435 19359\n",
      "0.40946329872404125\n",
      "0.8488683547147046\n",
      "0.5524464647361782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [10:09, 304.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    2     3     4 ... 96791 96792 96793] TEST: [    0     1     5 ... 96778 96781 96790]\n",
      "77435 19359\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2e20ae0c61aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mind1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mind2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-2e20ae0c61aa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mind1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mind2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=27)\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in tqdm(kf.split(ids)):\n",
    "    \n",
    "    train_index, test_index = item[0], item[1]\n",
    "    \n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "    \n",
    "    res = clf.predict(X[test_index])\n",
    "    \n",
    "    y_true = []\n",
    "    for i in test_index:\n",
    "        indices = [ok.index(cat) for cat in categories_dict[ids[i]]]\n",
    "        _y_true = np.zeros(len(ok), dtype=int)\n",
    "        for index in indices:\n",
    "            _y_true[index] = 1\n",
    "        y_true.append(_y_true)\n",
    "        \n",
    "\n",
    "    prec, rec, f1 = 0, 0, 0\n",
    "    for i in range(len(res)):\n",
    "        ind1 = [j for j in range(len(y_true[i])) if y_true[i][j] == 1]\n",
    "        ind2 = [j for j in range(len(res[i])) if res[i][j] == 1]\n",
    "\n",
    "        _y_true = [ok[j] for j in ind1]\n",
    "        _res =[ok[j] for j in ind2]\n",
    "\n",
    "        prec += metric(_res, _y_true)\n",
    "        rec += metric(_y_true, _res)\n",
    "\n",
    "\n",
    "    prec = prec / len(res)\n",
    "    rec = rec / len(res)\n",
    "    f1 = 2 * prec * rec / (prec + rec)\n",
    "    print(prec)\n",
    "    print(rec)\n",
    "    print(f1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тут custom knn + фильтрация результатов с помощью логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 96791 96792 96793] TEST: [    4     7    27 ... 96770 96779 96789]\n",
      "77435 19359\n",
      "Applied logistic regression\n",
      "0.1483269734896763\n",
      "0.8265121851528797\n",
      "0.2515164678997413\n",
      "14.784338033989359\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=27)\n",
    "\n",
    "train_index, test_index = 0, 0\n",
    "for item in tqdm(kf.split(ids)):\n",
    "    \n",
    "    train_index, test_index = item[0], item[1]\n",
    "    \n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "    \n",
    "    res = clf.predict(X[test_index])\n",
    "    \n",
    "    for i in range(len(test_index)):\n",
    "        X_left = sparse.vstack([X[test_index[i]]] * n_neighbors)\n",
    "        ind2 = [j for j in range(len(res[i])) if res[i][j] == 1]\n",
    "        X_full = sparse.hstack([X_left, class_centroids[ind2]])\n",
    "        #_res = clf_binlogreg.predict(X_full)\n",
    "        _proba = clf_binlogreg.predict_proba(X_full)\n",
    "        \n",
    "        #print(_proba)\n",
    "        _proba = _proba.transpose()[1]\n",
    "        _res = [1 if p > 0.3 else 0 for p in _proba]\n",
    "        #print(_res)\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "        for j, ind in enumerate(ind2):\n",
    "            if _res[j] == 0:\n",
    "                res[i][ind] = 0\n",
    "    \n",
    "    print(\"Applied logistic regression\")\n",
    "    y_true = []\n",
    "    for i in test_index:\n",
    "        indices = [ok.index(cat) for cat in categories_dict[ids[i]]]\n",
    "        _y_true = np.zeros(len(ok), dtype=int)\n",
    "        for index in indices:\n",
    "            _y_true[index] = 1\n",
    "        y_true.append(_y_true)\n",
    "        \n",
    "\n",
    "    prec, rec, f1, mean_res_len = 0, 0, 0, 0\n",
    "    for i in range(len(res)):\n",
    "        ind1 = [j for j in range(len(y_true[i])) if y_true[i][j] == 1]\n",
    "        ind2 = [j for j in range(len(res[i])) if res[i][j] == 1]\n",
    "        mean_res_len += len(ind2)\n",
    "        \n",
    "        _y_true = [ok[j] for j in ind1]\n",
    "        _res =[ok[j] for j in ind2]\n",
    "\n",
    "        prec += metric(_res, _y_true)\n",
    "        rec += metric(_y_true, _res)\n",
    "\n",
    "\n",
    "    prec = prec / len(res)\n",
    "    rec = rec / len(res)\n",
    "    f1 = 2 * prec * rec / (prec + rec)\n",
    "    print(prec)\n",
    "    print(rec)\n",
    "    print(f1)\n",
    "    print(mean_res_len / len(res))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
